{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from vertexai.preview import tokenization\n",
    "\n",
    "model_name = \"gemini-1.5-flash-001\"\n",
    "tokenizer = tokenization.get_tokenizer_for_model(model_name)\n",
    "\n",
    "pubmed_dataset_dir = 'datasets/pubmed/chunk'\n",
    "\n",
    "progress = tqdm(total=len(os.listdir(pubmed_dataset_dir)))  \n",
    "\n",
    "for filename in os.listdir(pubmed_dataset_dir):\n",
    "    progress.update(1)\n",
    "    \n",
    "    if not filename.endswith('.jsonl'):\n",
    "        continue\n",
    "    path = os.path.join(pubmed_dataset_dir, filename)\n",
    "\n",
    "    num_tokens_list = []\n",
    "    with open(path, 'r') as f:\n",
    "        data_list = f.readlines()   \n",
    "        for data in data_list:\n",
    "            data = json.loads(data)\n",
    "            num_tokens = tokenizer.count_tokens(data['contents']).total_tokens\n",
    "            num_tokens_list.append(num_tokens)  \n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] in data['contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['contents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.preview import tokenization\n",
    "\n",
    "model_name = \"gemini-1.5-flash-001\"\n",
    "tokenizer = tokenization.get_tokenizer_for_model(model_name)\n",
    "\n",
    "contents = \"Hello World!\"\n",
    "result = tokenizer.count_tokens(contents)\n",
    "print(result.total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer._compute_tokens(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Average number of tokens: {sum(num_tokens_list) / len(num_tokens_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 384)\n"
     ]
    }
   ],
   "source": [
    "from src.encoder.factory import encoder_factory, EncoderType\n",
    "\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "encoder = encoder_factory(EncoderType.SENTENCE_TRANSFORMER,\n",
    "  model_name = model_name)\n",
    "\n",
    "contents = [\n",
    "  \"Hello World!\",\n",
    "  \"This is a test.\"\n",
    "]\n",
    "result = encoder.encode_batch(contents)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataloaders.factory import dataloader_factory, SupportedDatasets\n",
    "pubmed_dir = 'datasets/pubmed_demo/chunk'\n",
    "\n",
    "dataloader = dataloader_factory(\n",
    "    dataset = SupportedDatasets.PUBMED,\n",
    "    data_dir = pubmed_dir,\n",
    "    batch_size=10,\n",
    ")\n",
    "\n",
    "for batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.vector_store.factory import vector_store_factory, VectorStoreType\n",
    "import numpy as np\n",
    "\n",
    "vector_store = vector_store_factory(\n",
    "    store_type = VectorStoreType.QDRANT,\n",
    "    index_name = 'test1',\n",
    "    embedding_dim = 10,\n",
    "    storage_path = 'temp'\n",
    ")\n",
    "\n",
    "idx_list = list(range(10))\n",
    "dummy_vectors = np.random.rand(10, 10)\n",
    "payloads = [\n",
    "    {\"title\": \"Hello World!\"} for _ in range(10)\n",
    "]\n",
    "\n",
    "batch = {\n",
    "    \"idx\": idx_list,\n",
    "    \"vectors\": dummy_vectors,\n",
    "    \"metadata\": payloads\n",
    "}\n",
    "\n",
    "vector_store.upsert_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Hello World!'}, {'title': 'Hello World!'}, {'title': 'Hello World!'}]\n"
     ]
    }
   ],
   "source": [
    "query_vector = np.random.rand(10)\n",
    "results = vector_store.query(query_vector, topk=3)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf temp\n",
    "!mkdir temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mufaddal/Library/Caches/pypoetry/virtualenvs/rag-race-ZJn2A-oj-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"As a large language model, I don't have personal opinions or beliefs, including on the meaning of life. The meaning of life is a question that has been pondered by philosophers and theologians for centuries, and there is no one definitive answer.  \\n\\nHere's a breakdown of how people have approached the question:\\n\\n* **Existentialism:**  Focuses on the individual's freedom and responsibility to create their own meaning in a meaningless universe.\\n* **Nihilism:**  Believes that life is inherently meaningless and that there is no purpose or objective truth.\\n* **Religion:**  Often defines the meaning of life through the context of a higher power, divine purpose, and/or an afterlife. \\n* **Humanism:**  Emphasizes human values, reason, and ethics as the foundation for meaning and purpose. \\n* **Hedonism:**  Focuses on maximizing pleasure and minimizing pain as the ultimate goal in life. \\n\\nUltimately, the meaning of life is a personal question.  It's something each individual must discover for themselves, drawing upon their own values, experiences, and beliefs. \\n\\nHere are some questions that might help you explore your own understanding of the meaning of life: \\n\\n* What brings you joy? \\n* What do you find meaningful and fulfilling?\\n* What are your goals and aspirations?\\n* What legacy do you want to leave behind?\\n\\nIt's a journey of self-discovery, and there's no right or wrong answer. \\n\"]\n"
     ]
    }
   ],
   "source": [
    "from src.llms.factory import llm_factory, LLMTypes\n",
    "\n",
    "model = llm_factory(\n",
    "    llm_type = LLMTypes.GEMINI,\n",
    "    model_name = \"gemini-1.5-flash-001\"\n",
    ")\n",
    "\n",
    "response = model(\"What is the meaning of life?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all __pycache__ directories recursively in the current directory\n",
    "!find . | grep -E \"(__pycache__)\" | xargs rm -rf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-race-ZJn2A-oj-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
